# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13z5PbRnzrlb8KRda3i52B__NzbnSQZVJ
"""

# app_bidirectional_sign_streamlit.py

import streamlit as st
import numpy as np
from tensorflow.keras.models import load_model
from rembg import remove
from PIL import Image
from gtts import gTTS
import os
import json
import io
import re

# ------------ CONFIG ------------
MODEL_PATH = "Mobile_98.keras"
CLASS_LABELS_PATH = "class_labels.json"
PLACEHOLDER_IMAGE = r"C:\Users\Gobi\Desktop\miniproject\BGremoved_clean_images\not sign.png"
# --------------------------------

# Load model and labels
model = load_model(MODEL_PATH)
with open(CLASS_LABELS_PATH, "r", encoding="utf-8") as f:
    class_labels = json.load(f)
class_labels = {int(k): v.strip() for k, v in class_labels.items()}

# Malayalam ‚Üí Tamil
MALAYALAM_TO_TAMIL_MAP = {
    "class_1  ‡¥Ö - A": "‡ÆÖ",
    "class_2  ‡¥Ü - AA": "‡ÆÜ",
    "class_3  ‡¥á -  I": "‡Æá",
    "class_4  ‡¥à - II": "‡Æà",
    "class_5  ‡¥â - U": "‡Æâ",
    "class_6  ‡¥ä - UU": "‡Æä",
    "class_8  ‡¥é - E": "‡Æé",
    "class_9  ‡¥è -  EE": "‡Æè",
    "class_10  ‡¥ê - AI": "‡Æê",
    "class_11  ‡¥í - O": "‡Æí",
    "class_12  ‡¥ì - OO": "‡Æì",
    "class_13  ‡¥î - AU": "‡Æî",
}

# Tamil ‚Üí Malayalam
TAMIL_TO_MALAYALAM_MAP = {
    "class_1  ‡ÆÖ": "‡¥Ö",
    "class_2  ‡ÆÜ": "‡¥Ü",
    "class_3  ‡Æá": "‡¥á",
    "class_4  ‡Æà": "‡¥à",
    "class_5  ‡Æâ": "‡¥â",
    "class_6  ‡Æä": "‡¥ä",
    "class_7  ‡Æé": "‡¥é",
    "class_8  ‡Æè": "‡¥è",
    "class_9  ‡Æê": "‡¥ê",
    "class_10  ‡Æí": "‡¥í",
    "class_11  ‡Æì": "‡¥ì",
    "class_12  ‡Æî": "‡¥î",
    "class_13  ‡ÆÉ": "‡¥Ö‡¥É",
}

# Reference images (simplified)
reference_images = {
    "class_1 ‡¥Ö - A": r"C:\Users\Gobi\Desktop\miniproject\BGremoved_clean_images\Tamil_class_01\frame_0001.jpg",
    "class_2 ‡¥Ü - AA": r"C:\Users\Gobi\Desktop\miniproject\BGremoved_clean_images\Tamil_class_02\frame_0001.jpg",
    "class_1  ‡ÆÖ": r"C:\Users\Gobi\Desktop\miniproject\BGremoved_clean_images\Malayalam_class_01\frame_0001.jpg",
    "class_2  ‡ÆÜ": r"C:\Users\Gobi\Desktop\miniproject\BGremoved_clean_images\Malayalam_class_02\frame_0001.jpg",
}

# ---------------- Utility Functions ----------------
def normalize_label(label):
    return re.sub(r'\s+', ' ', label.strip().lower())

def composite_on_black(pil_img):
    """Add black background to transparent image."""
    if pil_img.mode in ("RGBA", "LA") or ("transparency" in pil_img.info):
        bg = Image.new("RGB", pil_img.size, (0, 0, 0))
        bg.paste(pil_img, mask=pil_img.split()[-1])
        return bg
    return pil_img.convert("RGB")

def preprocess_for_model(pil_img, target_size=(128, 128)):
    img_resized = pil_img.resize(target_size)
    arr = np.array(img_resized).astype("float32") / 255.0
    if arr.ndim == 2:
        arr = np.stack([arr]*3, axis=-1)
    return np.expand_dims(arr, axis=0)

def get_translated_sign_name(raw_label: str):
    raw_label = raw_label.strip()
    if raw_label in MALAYALAM_TO_TAMIL_MAP:
        return MALAYALAM_TO_TAMIL_MAP[raw_label], "Malayalam ‚Üí Tamil"
    elif raw_label in TAMIL_TO_MALAYALAM_MAP:
        return TAMIL_TO_MALAYALAM_MAP[raw_label], "Tamil ‚Üí Malayalam"
    else:
        return "?", "Unknown"

# ---------------- Streamlit App ----------------
st.set_page_config(page_title="Bidirectional Sign Recognition", layout="centered")
st.title("ü§ü Tamil ‚Üî Malayalam Sign Language Recognition with Voice Output")

uploaded_file = st.file_uploader("Upload a Sign Image", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    st.image(uploaded_file, caption="Uploaded Image", use_column_width=True)

    # Process uploaded image
    img = Image.open(uploaded_file).convert("RGB")
    no_bg = remove(img)
    cleaned_rgb = composite_on_black(no_bg)

    # Prediction
    x = preprocess_for_model(cleaned_rgb)
    preds = model.predict(x)
    pred_idx = int(np.argmax(preds, axis=1)[0])
    confidence = float(np.max(preds))
    pred_label = class_labels.get(pred_idx, f"class_{pred_idx}")

    # Translation
    translated_name, translation_dir = get_translated_sign_name(pred_label)

    # Voice
    tts_path = "translated_voice.mp3"
    if re.search(r'[\u0D00-\u0D7F]', translated_name):
        tts = gTTS(text=translated_name, lang="ml")
    else:
        tts = gTTS(text=translated_name, lang="ta")
    tts.save(tts_path)

    # Reference image
    ref_path = PLACEHOLDER_IMAGE
    normalized = normalize_label(pred_label)
    for key, path in reference_images.items():
        if normalize_label(key) == normalized and os.path.exists(path):
            ref_path = path
            break

    # Show results
    st.subheader("üìä Prediction Results")
    st.write(f"**Predicted Class:** {pred_label}")
    st.write(f"**Confidence:** {confidence:.4f}")
    st.write(f"**Translation Direction:** {translation_dir}")
    st.write(f"**Translated Letter:** {translated_name}")

    col1, col2 = st.columns(2)
    with col1:
        st.image(cleaned_rgb, caption="Background Removed (Black BG)")
    with col2:
        st.image(ref_path, caption="Reference Image")

    st.audio(tts_path, format="audio/mp3")

else:
    st.info("Please upload an image to start recognition.")